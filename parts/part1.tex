%%==================================================
%% chapter01.tex for DUT Thesis 
%% version: 0.1
%% last update: Dec 25th, 2022
%%==================================================
\BiChapter{绪论}{Introduction}
绪论应包括本研究课题的学术背景及其理论与实际意义；本领域的国内外研究进展及成果、存在不足或有待深入研究的问题；本研究课题的来源及主要研究内容等。
\label{chap:part1}
\BiSection{研究背景与意义}{Research background}

随着互联网技术的迅猛发展，当今社会已迈入信息化时代。信息以各种形式呈现，包括文字、图像、音频和视频等。图像作为生动的信息表达方式在现实世界中起着重要作用。随着图像获取设备的不断进步，图像数据量急剧增长。研究者们希望利用计算机处理这些海量数据，以降低人工处理成本，形成了计算机视觉这一重要研究领域，吸引着大量研究者的探索。

在处理图像信息时，并非所有信息都是有效的。对图像全面处理会耗费大量计算资源，因此研究者们希望计算机能够像人类视觉系统一样，聚焦于主要信息，减轻计算负担。人类视觉系统能够快速定位到场景中感兴趣的目标区域，然后进一步加工处理，这被称为视觉注意力机制。这种机制使我们能够快速捕捉到场景的重要内容，提高信息处理效率。随着网络技术和图像采集设备的普及，我们每天接收大量图像数据。研究者期望计算机具备人类视觉注意力机制的能力，以提高图像数据处理效率，减少计算资源浪费。因此，显著性目标检测任务应运而生，旨在模拟人类视觉注意力机制，识别显著性目标或区域。

%这一任务在计算机视觉、计算机图形学和机器人技术等多个领域发挥着重要作用，为其他视觉任务提供有效帮助，并在各种任务中应用广泛。

显著性目标检测在计算机视觉、计算机图形学和机器人技术等领域扮演着关键角色。在计算机视觉领域中，显著性目标检测为其他视觉任务提供重要支持，在语义分割、目标检测以及目标追踪等任务中有广泛应用。在计算机图形学领域，它被运用于自动图像裁剪、图像重定位和视频摘要等任务。在机器人技术中，显著性目标检测被用于辅助人机交互和目标识别等任务。

当前的显著性目标检测方法基于输入数据类型不同，可分为三类：2D数据包括RGB图像，3D数据包括RGB-D图像，以及4D光场数据。随着深度卷积神经网络的进步，显著性目标检测已经从传统手工特征转向主动探索图像语义特征，性能得到明显提升。基于深度学习的2D显著性目标检测方法利用CNN挖掘RGB图像的特征，进而预测显著性图。然而，在面对一些挑战性场景时，由于缺乏足够的场景信息支持，2D方法可能产生错误预测。

相较于2D数据，3D数据包含更多空间信息，并且随着3D传感技术的发展而更易获取。基于深度学习的RGB-D显著性目标检测方法致力于融合深度特征和RGB特征，在推理显著图时考虑场景深度信息。许多RGB-D显著性目标检测方法因此获得较高检测性能，尤其在挑战性场景中表现突出。然而，3D方法受深度图质量影响，低质量深度图可能导致错误的预测，这是深度传感器采集问题带来的挑战。

相对于常规相机拍摄的RGB图像和RGB-D数据，光场相机捕捉的光场数据记录了更加全面和详尽的自然场景信息，包含深度线索、焦点线索和角度信息等。焦点堆栈数据是光场数据的一种表达方式，表示为一组在不同深度范围内聚焦的图像。现有研究表明，利用焦点堆栈数据的光场显著性目标检测方法在处理前景背景相似、复杂背景和小物体等具有挑战性场景时具有显著优势。然而，在实际场景中，光场数据获取成本高、处理多线索信息的成本高以及显著性像素级标注成本高，导致当前光场数据库样本数量较少。由于数据驱动的深度模型受数据限制，因此相同模型在训练数据较少的情况下会表现出较差的检测性能。因此，需要有效利用有限光场数据的网络模型，并通过增强当前光场数据集的算法来缓解这些问题。

因此，这篇文章将以有限数据驱动的光场显著性目标检测为研究重点，从网络模型和数据增强两个方面进行探索。首先，提出了区域感知网络，将焦点堆栈特征从全局整合到局部，更有效地利用现有光场数据。此外，还提出了一种基于数据增强的光场显著性目标检测方法，通过在重新组合显著性目标和背景的基础上合成新数据，从而扩充现有光场数据集。


\BiSection{国内外相关研究工作进展}{Research progress}

近年来，显著性目标检测作为计算机视觉领域的重要基础任务之一，已经成为研究的焦点之一。研究学者们提出了许多出色的检测模型，涵盖了RGB显著性目标检测、RGB-D显著性目标检测和光场显著性目标检测这三种类型。以下概述了近年来国内外该领域的研究进展。


\BiSubsection{RGB 显著性目标检测}{TODO}

目前的RGB显著性目标检测方法大致可以分为两类：传统方法和基于深度学习的方法。传统方法属于自底向上的方法，主要依赖各种颜色、纹理等低阶手工特征或对比度、中心环绕等启发式先验线索来识别显著性目标。这些传统方法的主要优势在于快速和适应性强，其中常见的显著性模型包括对比度先验、中心先验和对象性先验。对比度先验可分为局部对比度和全局对比度方法，前者主要通过像素或区域之间的对比度来定位显著性，而后者则考虑整个图像不同区域或像素之间的对比度。中心先验假设显著性对象通常位于图像中心，可用于优化显著性预测图。例如，经过全局对比模型生成初始显著性图后，可以利用中心先验模型进一步提升图像质量。对象性先验常用于改善粗略显著性图的性能，通过比较不同区域的特征来估计显著性图。


以上提及的方法利用确定性先验知识，在前景和背景对比度较高的场景中具有较高的检测准确性，但它们的泛化能力较差，对于不符合这些先验知识的场景，检测精度会明显下降。基于深度学习的方法属于自顶向下的方法，是一种数据驱动的方法，主要通过训练经过设计的网络模型来定位显著性目标，利用大规模带标签的数据库。由于卷积神经网络的发展，基于深度学习的检测方法的性能显著提高。一些方法集中在网络结构的设计上：DSS提出了多层特征密集连接的解码网络结构，结合不同尺度的特征以提高检测性能；R3Net提出了多层循环网络结构，通过迭代方式融合高阶和低阶特征，逐步优化预测结果；CPD设计了部分解码网络结构以提高检测速度而不影响性能。随着注意力机制的发展，一些方法利用注意力机制挖掘场景中的有效特征。例如，PiCANet结合了空间和通道注意力，将注意力模块嵌入多路循环网络以提高检测性能；PAGRN设计了渐进式的注意力引导模块，有选择性地整合多层特征的上下文信息。近年来，为了提高检测性能，一些显著性目标检测方法开始关注分割边界的性能，如将IOU损失用作惩罚损失来提高预测图的边界性能；另外，一些方法在网络中明确地对互补的显著性目标信息和显著边缘信息进行建模，以维持显著目标边界的预测精度。


\BiSubsection{RGB-D 显著性目标检测}{TODO}


在RGB-D的显著性目标检测领域，深度图提供丰富的空间信息，这为在许多复杂场景下的显著性目标检测性能带来了显著提升。传统的RGB-D检测方法通常依赖形状、三维布局等低阶特征来定位显著性目标。Peng等学者提出了多阶段的检测模型，结合深度信息和图像信息进行显著性预测。Ren等研究者将RGB-D视为4通道数据来计算局部对比度，并将对比信息与全局先验知识相结合，提出了基于两阶段的显著性目标检测框架。一些RGB-D检测方法基于特定假设来定位显著性目标，比如认为靠近相机的目标更容易被识别为显著性目标。Feng等学者根据这一假设，提出了一种局部背景封闭特征来识别显著性目标。这些方法证明了深度信息在显著性目标检测任务中的重要作用。然而，与传统RGB检测方法类似，这些方法存在泛化性较差的问题，当不满足先验知识或假设时，检测精度会明显下降。随着深度学习的进展，卷积神经网络能够提取深度图和RGB图像的高阶语义特征，从而大幅提升了RGB-D检测方法的性能水平。


基于深度学习的 RGB-D 检测方法通常先提取RGB-D数据的特征，然后融合不同模态的特征来定位显著性目标，许多研究致力于研究更有效的跨模态特征融合方式。根据融合方式的不同，现有的基于深度学习的 RGB-D 方法可以大致分为前期融合、后期融合和多级融合三种方式。前期融合策略是指先融合多模态信息，然后提取特征来预测显著性，Qu等研究者遵循这种方式，将RGB图像和深度图同时输入深度网络进行显著性预测。后期融合策略则是先提取多模态信息特征，然后融合这些特征来预测显著性，Shigematsu等学者采用后期融合方式，分别提取RGB图像和深度图的特征，然后将它们级联来定位显著性目标。与前述两种方式相比，多级特征融合在不同层级进行跨模态特征融合，使得不同层级的特征相互补充，在显著性目标检测任务中更为有效。Chen等研究者在PCA中采用多级特征融合方式，引入跨模态互补感知融合模块，考虑RGB和深度图之间的联系，在特征融合时获取更充分和有效的信息。Piao等研究者提出了深度诱导的多尺度注意力网络，结合深度特征和RGB特征以不同尺度上下文信息融合，实现了精准的显著性定位。此外，研究者们还积极探索除特征融合外的RGB-D检测方法。在CPFP中，Zhao等学者利用增强的深度信息来增强显著性目标与背景之间的对比度，并将其与RGB特征级联以预测显著性。Chen等研究者提出了一个自适应整合深度特征和RGB图像特征的注意力机制。


\BiSubsection{光场显著性目标检测}{TODO}


在光场显著性目标检测领域，光场数据能够记录目标场景的空间信息并提供准确的深度信息，从而缓解困难场景下检测准确性受限的问题。光场数据记录了自然场景更全面、更完整的信息，对于显著性目标检测任务具有积极作用，因此越来越多关于利用光场数据提升检测性能的研究开始涌现。传统光场显著性目标检测模型通常基于各种手工特征或先验假设来定位显著性目标，比如色彩对比度、背景先验等。大多数方法采用先进行粗糙预测，然后在细化处理的多阶段检测方式，而且大部分研究都是基于光场焦点堆栈数据展开探索。Li等研究者在 LFS 中首次在光场数据上实施了显著性目标检测，并构建了首个光场显著性检测数据集。LFS 结合了焦点聚焦和位置先验来确定背景与前景的焦点切片，然后通过背景先验计算出的显著性图与选定的焦点切片相结合来定位显著性目标。在WSC中，Li等人提出了一个可以处理2D、3D和4D光场数据的框架，利用非显著性字典对图像进行重构，并以高重构误差区域作为显著性字典，并通过迭代细化检测显著性目标。DILF 首先对光场数据进行超像素分割，然后通过计算深度线索对比度和RGB图像对比度生成显著性图，并利用背景先验增强显著性目标。Wang等学者提出了一个基于贝叶斯的显著性目标检测框架，能够有效整合从光场中提取的各种视觉特征。Zhang等研究者基于随机搜索策略，整合了全聚焦图像、深度图、焦点切片和多视角图像中的光场线索。与RGB方法以及RGB-D方法类似，传统的光场检测方法由于手工特征的泛化性较差，很难推广到较为困难的场景。



基于深度学习的光场显著性目标检测方法可以根据输入数据分为两类：一种是利用焦点堆栈数据的检测方法，另一种是利用多视角图像的检测方法。大部分基于深度学习的光场方法都专注于利用焦点堆栈来检测显著性目标，致力于寻找更有效的多模态特征融合手段。在DFS中，Wang等研究者利用ConvLSTM生成注意力向量，用于加权焦点切片特征和全聚焦图像特征，整合光场数据特征并预测显著性值。Piao等团队也运用ConvLSTM来探索光场数据，并创建了目前规模最大的光场显著性目标检测数据集。在LFNet中，Zhang等人提出了细化模块和整合模块，通过整合模块融合光场特征，并利用细化模块进一步优化显著性预测值。在PANet中，Piao等研究者提出了一种区域级的探索光场数据方法，并提出了相应的特征整合策略，利用光场的全局信息来缓解大物体多目标检测不准确的问题。另一方面，利用多视角图像进行显著性检测的深度学习模型致力于从不同视角间挖掘有效特征之间的关联。在DLSD中，Piao等学者将光场显著性目标检测拆分为两个子任务：通过合成多视角图像来检测显著性对象。而Zhang等研究者在MAC中采用多视角图像阵列进行光场显著性目标检测，并建立了一个新的多视角图像阵列的数据集，通过对不同视角图像角度变化建模，将提取的特征输入至DeepLabV2的结构中以捕获多尺度信息。


\BiSubsection{现存问题}{TODO}

由于深度学习的快速发展，网络模型能够提取出光场数据的高级语义特征，这导致光场显著性目标检测取得了显著的进展。对于跨模态特征融合，目前使用焦点堆栈数据的深度模型可以有效地融合多模态特征，并充分挖掘场景的几何关系。然而，深度学习方法是数据驱动的，因此用于光场显著性目标检测的深度模型性能受到数据量的影响。一般情况下，训练样本越多，模型的泛化能力就越好，检测效果也越强。不过，在实际场景中，获取光场数据需要多组摄像头或相机矩阵完成，这带来了极高的采集成本。而由于光场数据包含多个线索，如焦点堆栈、深度信息和多视角信息，处理这些数据的成本也很高。此外，为了进行显著性目标检测，需要对光场数据进行像素级标注，这需要耗费大量时间和精力。

这些问题导致现有光场显著性目标检测数据集非常稀缺，难以为现有深度学习算法提供足够的支持。因此，我们需要有效利用有限的光场数据来设计网络模型，并采用能够对有限光场数据进行增强的算法来解决上述问题。然而，当前的光场显著性目标检测方法通常在网络模型设计上引入全局注意力模块，专注于关注深度范围内与显著性目标距离较近的焦点切片特征，却忽略了焦点堆栈中其他切片的特征，导致光场中大部分信息未得到充分利用。同时，现有的数据增强方法通常使用传统的方式，如图像翻转、旋转、裁剪和颜色变换等，这些方法基于先验知识，无法覆盖所有可能的测试场景。

综上所述，基于有限数据的光场显著性目标检测研究面临着挑战，并需要进一步深入研究。


\BiSection{论文主要内容及结构安排}{TODO}
\BiSubsection{主要内容}{TODO}

本篇文章以显著性目标检测为核心内容，着眼于探索受限数据驱动的光场显著性检测方法。研究从两个方面入手，一是设计能有效利用有限光场数据的网络模型，二是构建有效增强光场数据的算法，以缓解数据稀缺的挑战。在关于如何设计适用于有限光场数据的深度检测网络模型方面，本文提出了一种新的区域感知网络。这个网络与目前方法中使用的全局注意力不同，它从局部角度出发，考虑了每个焦点切片中不同区域对显著性预测的作用，更充分地利用了有限的光场数据。多源学习模块结合显著性、边界和中心位置信息生成特征整合策略，针对焦点堆栈的特征进行区域级整合，聚焦性识别模块考虑多聚焦特性对显著性的影响，并更新整合策略以更好地突出显著性区域并抑制非显著性区域。

另一方面，关于如何设计有效增强光场数据的算法，本文提出了一种基于数据增强的光场显著性目标检测方法。相对于传统的数据增强方法，该方法引入了几何增强模块，通过结合图像修复网络和空间变换网络重新组合场景中的显著对象和背景，以尽可能扩增当前的光场数据集。聚焦性补偿模块则利用风格迁移网络进一步优化组合图像中焦点堆栈的真实性。此外，该方法还提出了一个不确定性学习策略，用于联合训练合成数据和真实数据，通过不同对待质量的合成数据，减小合成数据对网络训练的不利影响。

\BiSubsection{结构安排}{TODO}


第一章探讨了聚焦感知的光场显著性目标检测方法的背景和意义，以及对国内外显著性目标检测领域的研究现状与进展作了介绍。分析了目前方法中存在的问题与不足，并总结了本文的解决思路。

第二章详细介绍了相关理论知识，包括光场和光场显著性目标检测的理论基础。

第三章详细介绍了基于焦点感知的光场显著性目标检测方法。首先分析了现有光场显著性目标检测方法存在的问题，并阐述了研究的动机。随后介绍了所提出的网络模型，以及涉及到的多源学习模块、聚焦度识别模块和特征整合策略的具体实施方法。最后，展示了实验设置和结果分析，证明了所提出方法的卓越性能。

在第四章中，详细阐述了基于视角增强的光场显著性目标检测方法。探讨了增强光场数据的研究动机，并详细介绍了几何增强模块、聚焦性补偿模块和不确定性学习策略的具体实施方法。最后，呈现了实验设置和结果分析，以验证所提出方法的显著优势。

