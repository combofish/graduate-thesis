%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%\BiChapter{相关理论}{Related Theories}
%\BiSection{光场技术基本理论}{Basic Theory of Light Field Technology}

%\BiSubsection{光场成像原理}{Principles of Light Field Imaging}

%\BiSubsection{光场数据的可视化}{Visualization of Light Field Data}
%
%\BiSection{光场显著性目标检测相关理论}
%{Related Theories on Light Field Salient Object Detection}
%
%\BiSubsection{基于多视角图像的显著性目标检测原理}
%{Principles of Salient Object Detection via Multi-view Images}
%
%\BiSubsection{基于焦点堆栈的显著性目标检测原理}
%{Principles of Salient Object Detection via Focus Stack}
%
%\BiSubsection{显著性目标检测性能评估指标}
%{Performance Evaluation Metrics for Salient Object Detection}
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\BiChapter{相关理论}{Related Theories}
\label{chap:part2}

\BiSection{光场技术基本理论}{Basic Theory of Light Field Technology}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


光场的定义最早由A.Gershun\upcite{gershun1939light}教授提出，是空间中光线集合的完备表示，采集并显示光场就能在视觉上重现真实世界。
1991年，MIT的Edward H.Adelson教授和James R.Bergen\upcite{adelson1991plenoptic}教授指出人眼对光线的视觉感知可以认为是沿着单一函数的一个或多个方向的局部变化，描述了光照射到观察面的信息结构。
一旦定义了这个函数，各种潜在的视觉属性（如运动、颜色和方向）的测量就能够自动分离出来。
这个函数被称为全光函数，具有七个维度表示，具体公式如下：
\begin{equation}
	P(x,y,z,\theta,\varphi,\lambda,t)
\end{equation}
其中$(x,y,z)$表示发光物体的空间位置，$(\theta,\varphi)$分别表示传播光线入射的垂直角度和水平角度，$\lambda$表示传播光线的波长，发光物体所发射的光线信息随时时间$t$的推移而变化。
然而，这种能够记录空间中光线信息的七维全光函数过于复杂、数据量大，难以记录和存储，在实际计算中并未得到应用。
需要对其进行简化处理。
McMillan等\upcite{mcmillan2023plenoptic}在七维全光函数的基础上提出了
简化波长$\lambda$和时间$t$的更为方便的五维光场模型。
\begin{equation}
	P(x,y,z,\theta,\varphi)
\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure}[b]
	\centering
	\includegraphics[width=0.95\linewidth]{figures/chapter2/double_plane_model.drawio}
	\bicaption
	{光场双平面四参数模型\upcite{levoy2023light}}
	{Light field biplane four-parameter model\upcite{levoy2023light}}  
	\label{chapter2_fig1:double_plane}
\end{figure}


五维光场模型通过记录红、绿、蓝三原色来简化波长$\lambda$，以及通过记录不同帧来简化时间$t$。
实际上，光线在空间传播中，因传播距离而造成的信息损耗微乎其微，光场模型还可以进一步简化。
Levoy等\upcite{levoy2023light}忽略掉传播距离维度$z$得到四维光场模型，
同时提出光场渲染理论和双平面模型来描述静态的可见光，
如图~\ref{chapter2_fig1:double_plane}~所示。
双平面模型利用两个互相平行的参数化平面表示四维光场。
假设光线在没有遮挡物和散射介质的区域，忽略光线在传播过程中波长和时间维度的变化，
则任意一个包含位置和方向信息的光线都可以用双平面参数来表示，
空间中的光线穿过这两个平面分别相交于点$(u, v)$和点$(s, t)$，
光线即可用四维光场函数表示，其模型参数如下：
\begin{equation}
	P(u, v, x, y)
\end{equation}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


在光场成像设备中，可以用$(u, v)$表示光线与微透镜阵列的交点，用$(s, t)$表示光线与CCD传感器探测面的交点。
一条光线在整个四维空间中对应着光场的一个采样点。四维光场理论的推出为全光相机、相机阵列等设备提供了理论基础。目前，大多数单体全光相机和相机阵列的光场采集设备都遵循着四维光场理论。
%
%
%发展出了适用于光学系统的光场双平面参数特征。
%假设一条光线在两个不共面的平面$(u,v)$和平面$(s,t)$各有一个交点，则该光线可以用这两个交点唯一表示。
%光场是计算机科学领域的学者定义的“Light Field”，是指除了包含原图像矩阵中的空间坐标$(x,y)$和强度$I$外，还有光线入射的角度信息$(\theta,\varphi)$。
%光在传播过程中的各种潜在的视觉属性（如运动、颜色和方向）。




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\BiSubsection{光场成像原理}
{Principles of Light Field Imaging}




传统彩色图像的成像方式，是将从透镜入射的光线记录到成像平面上。
然而，光场成像采用不同的方式。
它是一种依靠数值计算的成像方式\upcite{levoy2023light}，
目的是在记录光照强度时，也能够反映出光线的入射方向。
为了得到可视化的图像信息，
需要对光场传感器获取的数据进行相应的数值计算处理。
随着光场成像技术的方法，
出现了几种不同的光场成像方式，
根据其成像原理的不同，
可以分为相机阵列光场成像、
时间序列光场成像、
空域复用成像和频域复用成像。





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\begin{figure}[b]
	\centering
	\includegraphics[width=1\linewidth]{figures/chapter2/camera_array}
	\bicaption{相机阵列光场成像}{Camera array for light field imaging}  
	\label{chapter2_fig2:camera_array}
\end{figure}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
（1）
相机阵列光场成像


%
%使用相机阵列获取光场信息是通过多个相机以特定的空间分布在不同视角下捕获场景图像的方法，
%
%每个相机捕获的是四维光场在其相对于场景方向上的二维投影。
%通过融合这些相机捕获的图像，就可以获得完整的四维光场数据。
%大尺度空间相机阵列主要应用于合成孔径成像以实现“透视”监测，或通过拼接实现大视角全景成像。
%相比之下，紧密排列的相机阵列则主要用于捕获高性能动态场景或场景的三维分布和结构等信息。
%光场数据的空间解析度取决于传感器本身，而角度解析度由传感器数量和布局方式确定。
%这种采集方法能够在单次曝光中瞬时捕捉光场，因此还能记录光场的时间序列信息。
%尽管这种成像方法空间解析度较高，但却带来了庞大的图像数据量，因此处理上更加耗时。
%此外，这种成像方式对多传感器的相对位置要求也较高。 
%


使用相机阵列获取光场信息是一种最为简易的方式，
通过排列多个普通平面相机组成相机阵列，如图~\ref{chapter2_fig2:camera_array}~所示。
每一个平面相机捕获的图像，隶属于四维光场中在固定角度位置的成像。
组合所有的图像构成图像阵列，就构成了完整的光场数据。
这种方式，需要每个平面相机具有相同的成像分辨率，
其视角差异跟相机阵列的排列相关，排列的紧密与否决定了形成光场数据的角度维度的精细程度。
同时，这种成像方式，需要校准每个相机的空间位置，实际实现上往往具有较大的空间误差，
因为每个相机需要在三维空间位置对齐，其接收入射光线的角度也需要固定，
实际使用时，容易在成像阶段引入噪声。
排列的阵列相机，存在木桶效应，即如果有一个相机无法正常工作，
其位置所在的行和列的其他相机所获取的光场信息都会受不同程度的损失。







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\begin{figure}[t]
	\centering
	\includegraphics[width=0.75\linewidth]{figures/chapter2/time_seq2}
	\bicaption{时间序列光场成像\upcite{levoy2023light}}
	{Time-series light field imaging\upcite{levoy2023light}}  
	\label{chapter2_fig3:time_seq2}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
（2）
时间序列成像


除了多个相机阵列排布外，Marc Levoy等人\upcite{levoy2023light}采用了单相机扫描系统。
他们通过让相机在固定的导轨上移动，
能够在不同的空间视角下拍摄图片，并添加时间信息，
最后将这些图像进行融合，从而实现相同的功能。
图~\ref{chapter2_fig3:time_seq2}~是典型的时序采集光场信息的示例。
与使用相机阵列的多传感器采集方式相比，
时间序列成像不局限于固定的空间位置，
能够实现低视差、高角度范围的图像采集，
但是，这种方法也有弊端，
即相机移动的控制结构需要高精度的控制，
同时，这些附加的空间坐标信息，角度信息也需要附加到图像数据中，
使得这种成像方式比较耗时。
这些确定使得这种图像采集方式更适合静态场景的光场信息获取。






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
（3）
微透镜光场成像


微透镜成像方式也叫空域复用成像方式，这是光场采集中常见的方式之一。
图~\ref{chapter2_fig4:microlens_for_lf_imaging}~展示了微透镜光场成像方式的工作原理。
普通的成像系统能够通过入射光线而成像，
微透镜光场成像扩展了普通成像系统，
为了获取不同视角的成像，
将微透镜阵列添加在普通成像系统的主透镜后，
每个微透镜都有相应的CMOD传感器记录光线信息，
就能获取不同空间位置和光线方向的四维光场数据。
微透镜成像方式具有空间体积小，成像设备便携易使用等特点，
一次拍摄就可以直接获取光场成像所需的全部数据。
这种成像方式最早在1992年由Adelson\upcite{adelson1992single}及其团队提出。
这种成像方式的缺点是视角差异有限，具体跟微透镜的数量相关，
且微透镜之间的距离固定。
后来出现了微透镜和传感器直接距离可调的光场相机结构，
使得能够设置主透镜的聚焦范围，实现了更为灵活的光场信息采集方式。




\begin{figure}[t]
	\centering
	\includegraphics[width=0.65\linewidth]{figures/chapter2/microlens_for_lf_imaging2.drawio}
	\bicaption{微透镜光场成像\upcite{adelson1992single}}
	{Microlens light field imaging\upcite{adelson1992single}}  
	\label{chapter2_fig4:microlens_for_lf_imaging}
\end{figure}






%
% 相机阵列的体积庞大，限制了其应用范围。
% 通过缩小相机阵列中各成像单元之间的基线，可以在单个相机框架下利用微透镜阵列来采集光场信息。
% 空域复用的成像方式通过在图像传感器上安装微透镜阵列来实现，这是光场采集中常见的方式之一，可通过单次曝光捕获光场信息。
%
%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\BiSubsection{光场数据的可视化}{Visualization of Light Field Data}

根据先前的描述，四维模型中双平面光场模型是目前广泛采用的光场模型，其中两个维度表示空间位置，另外两个维度表示方向角度。
在三维世界中，描绘四维光场数据是具有挑战性的，可以通过固定双平面光场模型的任意两个维度来展示二维切片以可视化光场数据。
虽然二维光场切片无法传达完整的光场信息，但可以帮助解释光场数据的内在特征。
固定角度维度可以获得子孔径图像阵列形式的光场数据；固定空间维度可以获得宏像素形式的光场数据；固定一个角度维度和一个空间维度可以获得包含空间和角度信息的 EPI 形式的光场数据。焦点堆栈数据也是一种光场可视化的形式。
常用的光场可视化方式主要有子孔径图像阵列形式、宏像素形式、极线图形式和焦点堆栈。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





（1）
子孔径图像


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





子孔径图像阵列视图是广泛使用的光场可视化方法之一。
固定角度维度$(u, v)$，令$u = u^{*}$，$ v = v^{*} $，
则$P(u^{*}, v^{*}, x, y) $表示在单个视点$(u^{*}, v^{*})$下的图像$(x,y)$。
若把$(x,y)$看成传统相机所成的像，$(u, v)$就表示相机所在的位置。
光场$P(u, v, x, y)$就可以理解为相机在视点平面等间隔采样，表现为相机不同视点$(u, v)$位置处所捕获的图像。
光场相机进行子孔径成像，
可以记录不同空间角度的彩色图像，
学名子孔径图像，
又被称为亚光圈图像，简称为视图。
如图~\ref{chapter2_fig5:multi_photo}~所展示。
图中右侧显示了以中心视点(5, 5)为基准的亚光圈图像的可视化图。




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.80\linewidth]{figures/chapter2/multi_photo}
	\bicaption{子孔径图像阵列形式的光场数据可视化}
	{Visualization of light field data in the form of subaperture image arrays}  
	\label{chapter2_fig5:multi_photo}
\end{figure}
%
%
%
%
\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.73\linewidth]{figures/chapter2/macro_photo}
	\bicaption{宏像素形式的光场数据可视化}
	{Visualizing light field data in macropixel form}  
	\label{cpt2_fig5:macro_photo}
\end{figure}
%
%
%multi_photo
%
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


（2）
宏像素视图


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



宏像素视图是另一种光场可视化形式。固定空间维度的坐标$(x, y)$，令$x=x^{*}$，$y=y^{*}$，
则$ P(u, v, x^{*}, y^{*})$可以表示为单个宏像素，
通过按照空间分辨率遍历所有宏像素，并按照图像顺序排列，形成宏图像。
如图~\ref{cpt2_fig5:macro_photo}~所示。
每个宏像素在宏图像中的分辨率代表了光场的角度分辨率。
%
不考虑遮挡的情况，$ P(u, v, x^{*}, y^{*})$表示场景中某一物点在所有视点下对应的像素值，
即$ P(u, v, x^{*}, y^{*})$表示光场采集设备所捕获到的物点发出的所有光线，
如图~\ref{cpt2_fig5:macro_photo}~中标号\ding{193}、\ding{194}的宏像素所示。
考虑遮挡的情况，$ P(u, v, x^{*}, y^{*})$可由场景中的某一遮挡物点，
在可视点下对应的像素点和在非可视点下其他物点对应的像素点的组合，
在图~\ref{cpt2_fig5:macro_photo}~中标号\ding{192}、\ding{195}的宏像素中，
可以看到宏像素内含有不同物点发出的光线。\par
%
%
%
%
%
\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.75\linewidth]{figures/chapter2/epi_photos}
	\bicaption{极视角形式的光场数据可视化}
	{Light field data visualization in polar perspective form}  
	\label{cpt2_fig6:epi_photos}
\end{figure}
%
%
%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



（3）极平面图


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



极平面视图
（Epipolar-Plane Images, EPI）
也是一种常用的光场数据可视化方式\upcite{1022496652.nh}。
在四维光场表示下，
分别固定一个角度维度和一个空间维度，
即可获取极平面视图表示。
具体来说，
当固定$(v, y)$坐标，令$v=v^{*}$，$y=y^{*}$，
则$ P(u, v^{*}, x, y^{*})$被称为固定$(v^{*}, y^{*})$的极平面图像，即垂直方向上的EPI图像。
同理，当固定$(u, x)$，则$ P(u^{*}, v, x^{*}, y)$被称为固定$(u^{*}, x^{*})$的极平面图像，
即水平方向上的EPI图像。
如图~\ref{cpt2_fig6:epi_photos}~所示，
基于四维度光场数据表示，
通过逐行索引像素或者逐列堆叠像素，即可形成极平面图，
如图中右侧和下侧所示，
得到的投影像素线能够提供明确准确的场景深度和遮挡信息。
这样堆叠出的像素平面图能够反应像素点在现实场景中的相对位置信息。









%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\begin{figure}[b]
	\centering
	\includegraphics[width=0.95\linewidth]{figures/chapter2/focal_stack}
	\bicaption{焦点堆栈形式的光场数据可视化}
	{Visualization of light field data as focus stack}  
	\label{cpt2_fig7:focal_stack}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



（4）
焦点堆栈



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



焦点堆栈是由不同散焦图片组成。
是目前常用的光场数据的中间表示格式。
不同的散焦图片具有局部聚焦的效果，如图~\ref{cpt2_fig7:focal_stack}~所示，
根据景深的不同，即不同散焦图片实际所属的聚焦平面的远近不同，
来依次排列出焦点堆栈。
在这些图像中，聚焦于物体深度的部分呈现清晰度，而非聚焦部分则显得模糊。
由于“近大远小”效应，不同图像之间存在放大比例差异。
放大比例记录了光线传播方向的信息，这些存在的放大比例可以进行光场的重投影。
但是一般并不仅仅使用焦点堆栈来表示完备的光场数据，
还会辅以全聚焦图，
即一张彩色图片，其场景中所示物体都是以清晰的状态呈现。
全聚焦图和焦点堆栈相辅相成，一个对于整体场景的清晰表示，
一个对应场景中不同景深下的局部表示。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%
%
%
%\textcolor{red}{TODO}
%
%搜集聚焦堆栈数据的方法包括移动镜头或探测器，以采集在不同成像平面上聚焦的图像序列。在这些图像中，聚焦于物体深度的部分呈现清晰度，而非聚焦部分则显得模糊。由于“近大远小”效应，不同图像之间存在放大比例差异。放大比例记录了光线传播方向的信息，只有在存在放大比例时才能进行光场的重投影；而利用光场重聚焦技术（例如，位移和叠加）生成的重聚焦数据则不包含放大比例信息，能够用于深度重建，但无法重新投影出完整的光场。然而，对于深度重建来说，放大比例本身并无实际帮助。
%
%
%
%当固定x=x0, u=u0时，按照空间和方向的顺序排列在一起，就可以得到垂直方向的EPI图像；当固定y=y0, v=v0时，通过改变x的u的顺序，就能得到水平方向的EPI图像。当物体满足朗伯体表现的性质，即向各个方向发出的光线强度相等时，那么该点在极平面图像中被表示为一条直线，该直线的斜率可以反映出该点的深度信息。图2.6展示了一个极平面图像的例子。
%
%
%通过逐个选择所有单视角图像，便可以构建多角度视图。单个视角图像类似于RGB图像，可以呈现所拍摄场景的空间信息。这种固定方向参数、遍历所有可选单视角图像的方法称为多视角图像的多视图表示。当设定代表光场空间的两个维度为x = x0，y = y0时，可以得到单个宏像素。通过按照空间分辨率遍历所有宏像素，并按照图像顺序排列，形成宏图像。
%每个宏像素在宏图像中的分辨率代表了光场的角度分辨率，属于多角度视图的角度域表示法。图中展示的3x3角度分辨率和空间分辨率的多角度视图示例，其中(a)表示多视图表示法，(b)代表角度域表示法。
%
%
%
%
%
%当设定代表光场方向的两个维度参数为u = u0，v = v0时，就可以获得单个视角图像。
%
%
%
%






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\BiSection{光场显著性目标检测算法原理}
{Principle of Light Field Salient Object Detection Algorithm}

%
%{光场显著性目标检测相关理论}
%{Related Theories on Light Field Salient Object Detection}
%
%
%
%
%
前文已指出，光场数据常用的
子孔径图像、
宏像素视图、
极平面图和
焦点堆栈
四种表示方式，其中宏像素视图成像出的多视角图像和焦点堆栈数据常用于显著性目标检测。
本小节探讨了基于这两种光场数据形式的显著性目标检测算法原理。



%，并介绍了评估光场显著性目标检测的指标。
%
%
%前文已指出，光场数据常用三种方式表示，其中多视角图像和焦点堆栈数据常用于显著性目标检测。
%本节首先探讨了基于这两种光场数据形式的显著性目标检测原理，并最后介绍了评估光场显著性目标检测的指标。
%常用的光场可视化方式主要有子孔径图像阵列形式、宏像素形式、极线图形式和焦点堆栈。






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\BiSubsection{基于多视角图像的显著性目标检测原理}
{Principles of Salient Object Detection via Multi-view Images}


基于多视角图像的显著性目标检测方法主要利用视差与深度之间的关系，在网络模型中引入了场景结构的线索。
通常，通过编码网络来提取多视角图像的高阶和低阶特征，并结合深度线索挖掘出的角度特征来定位显著性目标。
多视角图像的深度线索是通过不同视角之间的视差引入的。

\begin{figure}[b]
	\centering
	\includegraphics[width=0.90\linewidth]{figures/chapter2/microlens_array_imaging.drawio}
	\bicaption{基于微透镜阵列的光场相机成像原理\upcite{adelson1992single}}
	{Imaging principle of light field camera based on microlens array\upcite{adelson1992single}}  
	\label{cpt2_fig8:multi_array}
\end{figure}

具体来说，如图~\ref{cpt2_fig8:multi_array}~所示，
在观察同一目标$P$时，考虑两个视角 $v_{1}$ 和 $v_{2}$，
目标经过主透镜成像后形成像素点$P'$，
其中目标$P$到主透镜的距离为$Z$，而$Z'$表示主透镜到聚焦平面的距离，
主透镜到成像点的距离为$F$，主透镜到微透镜阵列的距离为$F'$。
两视点之间的距离用$H$表示，由此可推导出如下几何关系：
%
%
\begin{equation}
	\frac{D}{H} = \frac{F'}{Z'} - \frac{F'}{Z} 
	\label{cpt2_fac1:relate}
\end{equation}
%
%
其中$D$表示视差，$F'$、$H$和$Z'$都是相机内参，用来计算目标$P$点的深度。
从公式~\ref{cpt2_fac1:relate}~可以看出，
相机的成像参数对于如何成像发挥着重要作用。


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{figure}[t]
	\centering
	\includegraphics[width=0.85\linewidth]{figures/chapter2/multi_images_fssod}
	\bicaption{基于多视角图像的光场显著性目标检测模型\upcite{jing2021occlusion}}
	{Light field salient object detection model based on multi-view images\upcite{jing2021occlusion}}  
	\label{chpt2:figure:model_of_multi_inputs}
\end{figure}




现有基于多视角输入的光场显著性检测网络如图~\ref{chpt2:figure:model_of_multi_inputs}~所示。
Jing等学者提出OBGNet\upcite{jing2021occlusion}，从水平和垂直的多视角图中提取遮挡边界特征，
同时设计了一种级联解码器，用于生成显著边缘预测和显著对象预测来细化相互编码过程中的特征。
Zhang等人\upcite{zhang2020multi}提出MTCNet，
通过0、45、90、135四个角度的多视角图片导出深度的显著特征，并通过3D卷积建模多视角图像之间的视差相关性，
在解码阶段，提出了特征增强的显著对象生成器来集成这些互补的显着特征，从而产生光场的最终显着对象预测。
Zhang等研究者\upcite{zhang2022exploring}所提出的 ESCNet网络，
通过组合网络来实现光场显著性目标检测。
先使用网络进行光场原生数据的高维特征提取，生成可靠的4D光场信息；
再构造网络合成每一个多视角切片的显著语义信息
充分利用多个视点之间的空间相关性，构造基于信息整合的光场显著性目标检测网络。






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\BiSubsection{基于焦点堆栈的显著性目标检测原理}
{Principles of Salient Object Detection via Focus Stack}

  
当前，大多数光场显著性目标检测算法使用混合模态来构建网络，
网络可以同时输入全聚焦图片和焦点堆栈.
这种方法主要依赖于多焦特性，即场景聚焦于焦点堆栈中不同深度的目标，
通过探索其中蕴藏的场景结构信息，
来增强网络对于图片中场景的理解，以生成高质量的显著性预测图。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


早期的光场显著性目标检测还未引入深度卷积神经网络，
提取光场数据的特征使用硬性的手动处理，
依赖不同的色彩、对比度、区域等先验信息来编码全聚焦图像，
然后逐帧处理焦点堆栈序列，通过点扩散函数表示每张散焦图片的聚焦程度，
来综合判断场景中的显著性物体。
本文通过PANet\upcite{piao2021panet}模型来阐述这一方式的原理。
在PANet中，网络通过相比图片帧更细化的方式，即区域级的聚焦度量方式，
其通过全聚焦支路的特征信息与每个焦点堆栈图片语义特征的比较，
来判断不同散焦图片中显著清晰区域的位置，
最后将这些不同区域的特征权重加以整合，
进行两个支路的信息融合，如图~\ref{cpt2_fig9:model_of_fs_inputs}~中所示，
就能实现网络对于聚焦区域的场景感知。


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




基于Transformer架构的光场显著性目标检测网络，
通常依赖Transformer架构的长距离建模能力，
在网络的解码器添加Transformer块来聚合全部焦点堆栈的信息。
以LFTransNet网络\upcite{liu2023lftransnet}为例，
网络通过可学习的权重作为查询，输入到Transformer块中，查询
全部焦点堆栈特征来学习一个差异化通道权重，
经过若干层特征提取后，将这个差异化权重加权到焦点堆栈特征上，
来增强焦点堆栈特征的显著性表示，
最后再融合两个支路的预测信息，
并通过显著性预测头产生最终的显著性预测。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\begin{figure}[t]
	\centering
	\includegraphics[width=0.70\linewidth]{figures/chapter2/model_of_fs_inputs}
	\bicaption{基于焦点堆栈的光场显著性目标检测模型\upcite{piao2021panet}}
	{Light field salient object detection model based on focus stack\upcite{piao2021panet}}  
	\label{cpt2_fig9:model_of_fs_inputs}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\BiSection{显著性目标检测性能评估指标}
{Performance Evaluation Metrics for Salient Object Detection}



为了全面评估各种显著性目标检测模型在不同数据集上的分割性能，
本节将介绍显著性目标检测任务中广泛使用的五种评估指标。
分别包括
平均绝对误差（Mean Absolute Error，MAE）、
精确率-召回率曲线（P-R曲线）、
F-measure\upcite{achanta2009frequency}、
加权的F-measure\upcite{margolin2014evaluate}、
E-measure\upcite{fan2018enhanced}和
S-measure\upcite{fan2017structure}。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
（1）平均绝对误差\par
平均绝对误差通过衡量显著性预测图与相应的真实值之间的平均每个像素点绝对差异来
直观的评估显著性图的质量。
它是评估预测质量的最简单有效的方式。
该评估指标的公式如下：
\begin{equation}
	MAE=\frac{1}{W \times H}\sum_{i=1}^{W} \sum_{j=1}^{H} \left |  \hat{S} (i,j) - S(i,j)\right | 
\end{equation}
%
%
其中$\hat{S}(i,j)$和$S(i,j)$分别表示显著性预测图和相应真值图对应坐标的像素。
值得一提的是，当该性能指标的值越高时，意味着预测图与真值图的差异越大；
反之，当该性能指标的值越低时，意味着预测图越接近真值图，即网络的预测性能越好。




平均绝对误差展现了出色的可解释性，因为它直接展示了模型预测值与实际值之间的差异大小，
有助于让研究者更加直观地评估模型的性能。
需要留意的是，平均绝对误差对异常值比较敏感，因为它会均等对待每个样本的误差。
若数据集包含异常值，这将会对平均绝对误差的计算结果造成较大影响。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
（2）精确率-召回率曲线（P-R曲线）\par
%
%
P-R 曲线是用来评估预测图的精准率和召回率的工具。
%P-R曲线就是精确率和召回率的曲线，
曲线以召回率作为横坐标轴，以精确率作为纵坐标轴。
在评估二分类任务时，通常会构造混淆矩阵加以分析，
精确率和召回率可以从混淆矩阵中计算而来，公式如下：
%
%
\begin{equation}
	Precision = \frac{TP}{TP + FP},~Recall = \frac{TP}{TP+FN}
\end{equation}
%
%
其中分类器把正例正确地分类为正例TP（True Positive），
把正例错误地分类为负例，标记为FN（False Negative），
把负例正确地分类为负例，用TN（True Negative）表示，
FP（False Positive）表示
把负例错误分类为正例。


在实验过程中，算法对样本进行分类时，都会有置信度，
置信度大于阈值的时候，即表示该样本是正样本的概率，
比如网络预测样本A的置信度是0.99，
样本B的置信度是0.45。
%则表示网络认为样本Ａ是正例，0.01的概率表示网络认为样本B是正例。
通过选择合适的阈值，比如以0.5为阈值对样本进行划分，
预测置信度大于0.5的样本A就被网络认为是正例，小于0.5的置信度样本B就被网络判断为负例。
通过置信度就可以对所有样本进行排序，再逐个样本的选择阈值，
在该样本之前的都属于正例，该样本之后的都属于负例。
每一个样本作为划分阈值时，都可以计算对应的Precision和Recall，
那么就可以以此绘制P-R曲线。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
（3）
F-measure



F-measure是通过精确度和召回率的加权调和均值来计算的。
P-R曲线绘制时，需要根据不同的阈值来对预测结果的像素置信度进行二值化，
阈值的变化会导致评估精度出现波动。
精确率和召回率更关注的是正例的预测质量，
在类别不平衡的数据样本上，比如正样本远大于负样本的情况，P-R曲线可能出现过分乐观的估计结果。
为了综合考虑精准率和召回率之间的相关关系，
研究人员提出了 F-measure，该指标能够同时考量正例和负例的贡献。
评估指标的公式如下：
%
%
\begin{equation}
	F_{\beta} = \frac{\left ( 1 + \beta^{2} \right ) \times Precision \times Recall }{\beta^{2} \times Precision + Recall } 
\end{equation}
%
%
在上述公式中，Precision 和 Recall 分别代表精准率和召回率。
它们采用了自适应阈值以避免评估过程中的波动，其中$\beta$表示精准率和召回率之间的权重，
通常将$\beta^{2}$设置为 0.3。
该性能指标的越高表示预测结果越好。
F-measure之所以受人青睐在于其综合考量了精确率和召回率，
因此在处理一些不平衡的数据集和样本分布较为复杂的情况下具有很好的适用性。
然而，由于F-measure对于精确率和召回率的平衡要求较高，
可能在某些情况下导致难以准确评估模型的性能。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
（4）
加权的F-measure\par
%
%
加权F-measure克服了依赖缺陷、等重要缺陷和插值缺陷\upcite{margolin2014evaluate}。也是评估显著性预测图时经常会使用的评价指标。其公式如下：
\begin{equation}
	F_{\beta}^{w} = \frac{\left ( 1 + \beta^{2} \right ) \times Precision^{w}  \times Recall^{w} }{\beta^{2} \times Precision^{w} + Recall^{w} } 
\end{equation}
%
%
其中$w$是基于欧几里得距离的加权函数。
加权F-measure综合考虑了模型在不同类别上的性能表现，
对于不同类别样本数量不同的情况也很合适。
一般而言，加权F-measure相比简单平均F-measure更准确地评估了模型的性能。
加权F-measure的数值越高，意味着模型性能越好。




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
（5）
E-measure


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




E-measure是
2018年提出的用于评估二分类图片的指标。
该指标考虑了图片的局部像素值与整体像素的平均值，
相比其他评估方法，其与人类判断之间具有很高的排序一致性。
该指标的公式如下：
%
%
\begin{equation}
	E_{\phi } = \frac{1}{w \times h} \sum_{i=1}^{w} \sum_{j=1}^{h} \phi\left ( i,~j \right ) 
\end{equation}
%
%
%
%
其中$\phi\left (\cdot \right ) $代表增强的对齐矩阵，
其值越大，比较的两张预测图越相似，表明网络预测的效果越好。
$w$和$h$表示图像的尺寸。
E-measure展现了良好的稳定性和解释性，
有助于对显著性目标检测等图像分割算法的性能进行相对准确的评估。
然而，它对误差容忍度和边缘细化系数的选择相当敏感，
因此需要根据具体情况进行调整。
另外，E-measure仅适用于二值图像分割问题，
无法直接用于其他类型的分割问题。




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
（6）
S-measure


S-measure 是一种评估两个图片之间纹理相似性的度量。
相较于平均错误率这种只能评估像素点之间累计差异的评价指标，
S-measure 能够更多的考虑图片中区域结构、纹理的相似性。
具体实现上，对于两张给定的图片数据，
先以7x7划分小窗格，每个小窗格可以理解为一个局部区域，
通过相对应局部区域的结构相似性比对（Structural Similarity，SSIM），
得到区域级的相似程度，在对整张图片进行加权求平均，
得到图片级的结构相似度。
S-measure的公式如下：



\begin{equation}
	S_{\alpha} = \alpha * S_{o} + \left ( 1 - \alpha  \right )*S_{r} 
\end{equation}
%
%
其中，$S_{o}$代表对象级的结构相似性，$S_{r}$代表区域级的结构相似性，
而$\alpha$则用于平衡$S_{o}$和$S_{r}$的影响。
通常来说，根据Fan等人\upcite{fan2018enhanced}的设定，
$\alpha$被设定为0.5。
很显然，对于与真值越接近的显著性预测图，S-measure值就越高。



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\BiSection{本章小节}{The Chapter’s Conclusion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





本章首先以一个发展的角度，介绍了光场技术的由来、各个具有开拓创新的阶段，
并以可视化的方式呈现了不同光场成像方式的效果。
之后，
介绍了应用光场显著性目标检测算法所必须的相关理论，
并分小结描述了以多视角图作为输入
和以焦点堆栈作为网络输入的
光场显著性目标检测算法的流程。
最后，展开介绍了显著性检测领域中广泛认可的网络性能评价指标。






































%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% Split paragraphs
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

